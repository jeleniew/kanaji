{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "FOLDER_PATH = os.getenv(\"FOLDER_PATH\")\n",
    "files = [f\"{FOLDER_PATH}_{i:02d}\" for i in range(1, 51)]\n",
    "OUTPUT_PATH = os.getenv(\"OUTPUT_PATH\")\n",
    "selected_jis = [9250, 9252, 9254, 9256, 9258]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Record:\n",
    "    \"\"\"One record from a file ETL9G.\"\"\"\n",
    "    jis_code: int\n",
    "    img: np.ndarray\n",
    "\n",
    "\n",
    "def swap_white_and_black(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Swaps white and black pixels in the image.\n",
    "    \"\"\"\n",
    "    return 15 - img\n",
    "\n",
    "\n",
    "def clean_image_background(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Removes unwanted objects that touch the edges of the image.\n",
    "    This helps eliminate neighboring fragments that result from scanning multiple samples from one sheet.\n",
    "    Uses bfs to find connected components touching the edges and removes them.\n",
    "    \"\"\"\n",
    "    # TODO: remove small objects inside the image\n",
    "    # TOOD: check y and x order\n",
    "    h, w = img.shape\n",
    "    visited = np.zeros((h, w), dtype=bool)\n",
    "\n",
    "    def bfs(start_x: int, start_y: int):\n",
    "        queue = [(start_x, start_y)]\n",
    "        while queue:\n",
    "            x, y = queue.pop(0)\n",
    "            if visited[x, y]:\n",
    "                continue\n",
    "            visited[x, y] = True\n",
    "            if img[x, y] > 0:\n",
    "                img[x, y] = 0\n",
    "                for dx, dy in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n",
    "                    nx, ny = x + dx, y + dy\n",
    "                    if 0 <= nx < h and 0 <= ny < w and not visited[nx, ny]:\n",
    "                        queue.append((nx, ny))\n",
    "\n",
    "    for i in range(h):\n",
    "        if not visited[i, 0]:\n",
    "            bfs(i, 0)\n",
    "        if not visited[i, w - 1]:\n",
    "            bfs(i, w - 1)\n",
    "    for i in range(w):\n",
    "        if not visited[0, i]:\n",
    "            bfs(0, i)\n",
    "        if not visited[h - 1, i]:\n",
    "            bfs(h - 1, i)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def cut_center_and_scale(img: np.ndarray, add_margin: bool = False) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Cuts the center of the image and scales it to a fixed size.\n",
    "    \"\"\"\n",
    "    mask = img > 1\n",
    "    coords = np.argwhere(mask)\n",
    "\n",
    "    if coords.size == 0:\n",
    "        return img\n",
    "    \n",
    "    # TODO: check if +1 is needed\n",
    "    y0, x0 = coords.min(axis=0)\n",
    "    y1, x1 = coords.max(axis=0) + 1  # slices are exclusive at the top and bottom\n",
    "    cropped_img = img[y0:y1, x0:x1]\n",
    "    ch, cw = cropped_img.shape\n",
    "    if add_margin:\n",
    "        cropped_img = np.pad(cropped_img, pad_width=2, mode='constant', constant_values=0)\n",
    "\n",
    "    scale = min(127 / ch, 128 / cw)\n",
    "    new_h = int(ch * scale)\n",
    "    new_w = int(cw * scale)\n",
    "\n",
    "    scaled_img = tf.image.resize(\n",
    "        cropped_img[..., np.newaxis],\n",
    "        (new_h, new_w), method='bilinear'\n",
    "    ).numpy()\n",
    "    \n",
    "    canvas = np.zeros((127, 128, 1), dtype=scaled_img.dtype)\n",
    "\n",
    "    y_offset = (127 - new_h) // 2\n",
    "    x_offset = (128 - new_w) // 2\n",
    "    canvas[y_offset:y_offset+new_h, x_offset:x_offset+new_w, :] = scaled_img\n",
    "\n",
    "    return canvas.astype(np.uint8).squeeze()\n",
    "\n",
    "\n",
    "def convert_to_binary_image(img: np.ndarray, threshold = 3) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts grayscale image to binary (black and white) image using thresholding.\n",
    "    \"\"\"\n",
    "    binary_img = np.where(img > threshold, 15, 0).astype(np.uint8)\n",
    "    return binary_img\n",
    "\n",
    "\n",
    "def smooth_edges(img: np.ndarray, kernel_size: int = 7) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Smooths the edges of the image using Gaussian blur.\n",
    "    \"\"\"\n",
    "    img = cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "    return img\n",
    "\n",
    "\n",
    "def thin_lines(img: np.ndarray, kernel_size: int = 2) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Thins the lines in the image using morphological operations.\n",
    "    \"\"\"\n",
    "    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "    img = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 187ms/step - accuracy: 0.5775 - loss: 4.4747 - val_accuracy: 0.8400 - val_loss: 0.6131\n",
      "Epoch 2/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 189ms/step - accuracy: 0.8225 - loss: 0.4667 - val_accuracy: 0.8750 - val_loss: 0.4090\n",
      "Epoch 3/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 168ms/step - accuracy: 0.9050 - loss: 0.2850 - val_accuracy: 0.9050 - val_loss: 0.3073\n",
      "Epoch 4/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 162ms/step - accuracy: 0.8988 - loss: 0.2652 - val_accuracy: 0.9100 - val_loss: 0.3485\n",
      "Epoch 5/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 178ms/step - accuracy: 0.9225 - loss: 0.2128 - val_accuracy: 0.9250 - val_loss: 0.3283\n",
      "Epoch 6/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 176ms/step - accuracy: 0.9337 - loss: 0.1863 - val_accuracy: 0.9350 - val_loss: 0.3141\n",
      "INFO:tensorflow:Assets written to: models/cnn_etl9g_5s_50e_nomargin_smooth_simple\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/cnn_etl9g_5s_50e_nomargin_smooth_simple\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'models/cnn_etl9g_5s_50e_nomargin_smooth_simple'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 127, 128, 1), dtype=tf.float32, name='keras_tensor_896')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 5), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2724535486224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2724535488528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2724535491792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2724535492560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2724535485264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2724535498896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2724535495632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2724535490448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2724535495824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2724535484688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from typing import BinaryIO, List, Optional\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dataclasses import dataclass\n",
    "import struct\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "@dataclass\n",
    "class Record:\n",
    "    \"\"\"One record from a file ETL9G.\"\"\"\n",
    "    jis_code: int\n",
    "    img: np.ndarray\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "def read_etl9g_records_from_file(f: BinaryIO) -> Optional[Record]:\n",
    "    \"\"\"\n",
    "    Reads one record from a file ETL9G.\n",
    "    Returns: (jis_code, img)\n",
    "    \"\"\"\n",
    "    s = f.read(8199)\n",
    "    if not s:\n",
    "        return None\n",
    "    r = struct.unpack('>HH8sIBBBBHHHHBB34s8128s7x', s)\n",
    "    jis_code = r[1]\n",
    "    img_bytes = r[15]\n",
    "    \n",
    "    arr = np.frombuffer(img_bytes, dtype = np.uint8)\n",
    "    high = arr >> 4\n",
    "    low = arr & 0x0F\n",
    "    pixels = np.empty(arr.size * 2, dtype = np.uint8)\n",
    "    pixels[0::2] = high\n",
    "    pixels[1::2] = low\n",
    "    img = pixels.reshape(127, 128)\n",
    "\n",
    "    return Record(jis_code, img)\n",
    "\n",
    "\n",
    "def read_etl9g_all_records() -> List[Record]:\n",
    "    \"\"\"\n",
    "    Reads multiple files ETL9G binary\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    for file in files:\n",
    "        with open(file, \"rb\") as f:\n",
    "            while True:\n",
    "                record = read_etl9g_records_from_file(f)\n",
    "                if record == None:\n",
    "                    break\n",
    "                if record.jis_code in selected_jis:\n",
    "                    img = record.img\n",
    "                    \n",
    "                    simple_record = Record(record.jis_code, simple_preprocess(img))\n",
    "                    records.append(simple_record)\n",
    "\n",
    "                    # strong_record = Record(record.jis_code, preprocess(img))\n",
    "                    # records.append(strong_record)\n",
    "\n",
    "    return records\n",
    "\n",
    "\n",
    "def simple_preprocess(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Simple preprocessing steps.\n",
    "    \"\"\"\n",
    "    img = clean_image_background(img)\n",
    "    img = cut_center_and_scale(img)\n",
    "    # img = smooth_edges(img)\n",
    "    img = convert_to_binary_image(img)\n",
    "    img = swap_white_and_black(img)\n",
    "    return img\n",
    "\n",
    "def preprocess(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Repeated preprocessing steps to get the best result.\n",
    "    \"\"\"\n",
    "    img = thin_lines(img, kernel_size=2)\n",
    "    img = clean_image_background(img)\n",
    "    img = cut_center_and_scale(img)\n",
    "    img = smooth_edges(img)\n",
    "    img = convert_to_binary_image(img, 3)\n",
    "    img = cut_center_and_scale(img, add_margin=True)\n",
    "    img = smooth_edges(img)\n",
    "    img = convert_to_binary_image(img, 6)\n",
    "    img = swap_white_and_black(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def create_cnn(with_augmentation=True):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Input(shape=(127, 128, 1)))\n",
    "\n",
    "    if with_augmentation:\n",
    "        model.add(tf.keras.Sequential([\n",
    "            layers.RandomRotation(0.1),\n",
    "            layers.RandomZoom(height_factor=(-0.1, 0.0), width_factor=(-0.1, 0.0)),\n",
    "            # layers.RandomTranslation(0.1, 0.1),   # not needed because images are centered\n",
    "            # layers.RandomFlip(\"horizontal\")       # shouldn't be used for writing\n",
    "        ]))\n",
    "\n",
    "    model.add(layers.Conv2D(32, (3,3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    model.add(layers.Conv2D(64, (3,3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    model.add(layers.Conv2D(128, (3,3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(len(selected_jis), activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def split_data(records: List[Record]) -> tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Splits the data into training and testing sets.\n",
    "    \"\"\"\n",
    "    images = np.array([record.img for record in records])\n",
    "    labels = np.array([selected_jis.index(record.jis_code) for record in records])\n",
    "\n",
    "    images = images[..., np.newaxis]  # add channel dimension\n",
    "\n",
    "    images_train, images_test, labels_train, labels_test = train_test_split(\n",
    "        images, labels, test_size=0.2, random_state=42, stratify=labels\n",
    "    )\n",
    "\n",
    "    return images_train, images_test, labels_train, labels_test\n",
    "\n",
    "\n",
    "def save_model(model: tf.keras.Model, path: str):\n",
    "    \"\"\"\n",
    "    Saves the model to the specified path.\n",
    "    \"\"\"\n",
    "    model.export(path)\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model(path)\n",
    "    tflite_model = converter.convert()\n",
    "    with open(f\"{path}.tflite\", \"wb\") as f:\n",
    "        f.write(tflite_model)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    records = read_etl9g_all_records()\n",
    "    images_train, images_test, labels_train, labels_test = split_data(records)\n",
    "\n",
    "    model = create_cnn(with_augmentation=True)\n",
    "    # TODO: check if summary needed\n",
    "    # model.summary()\n",
    "    history = model.fit(\n",
    "        images_train, labels_train,\n",
    "        validation_data=(images_test, labels_test),\n",
    "        epochs=50,\n",
    "        shuffle=True,\n",
    "        callbacks=[early_stop]\n",
    "    )\n",
    "    plt.plot(history.history['val_loss'])\n",
    "\n",
    "    model_no_augmentation = create_cnn(with_augmentation=False)\n",
    "    model_no_augmentation.set_weights(model.get_weights())\n",
    "    save_model(model_no_augmentation, f\"{OUTPUT_PATH}/cnn_etl9g_5s_50e_nomargin_smooth_simple\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
